{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JI8px5mkGMkB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron(nn.Module):\n",
        "  def __init__(self, input_size, activation):\n",
        "    super(Perceptron, self).__init__()\n",
        "    self.w = nn.Parameter(torch.randn(input_size))\n",
        "    self.b = nn.Parameter(torch.randn(1))\n",
        "    self.activation = activation\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.activation(x @ self.w + self.b)"
      ],
      "metadata": {
        "id": "wxD8TzcWGO_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = Perceptron(3, torch.sigmoid)"
      ],
      "metadata": {
        "id": "-GFUt4QGHIG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor([1, 2, 3], dtype = torch.float32)\n",
        "p1(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgwmdeJXHOy1",
        "outputId": "904561a5-bab5-420a-aebd-9b24aaf4091a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0204], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 431
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p1.parameters().__next__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onjATlmlHR3p",
        "outputId": "bb8f7bdf-6720-48b7-9cea-52f99ef02218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([ 0.5300, -1.9257,  0.7713], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 432
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseLayer(nn.Module):\n",
        "  def __init__(self, input_size, output_size, activation):\n",
        "    super(DenseLayer, self).__init__()\n",
        "    self.layer = nn.ModuleList([Perceptron(input_size, activation) for i in range(output_size)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.stack([p(x) for p in self.layer], dim=1)"
      ],
      "metadata": {
        "id": "6eATuYpHICmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([3, 4, 5], dtype = torch.float32)\n",
        "\n",
        "layer1 = DenseLayer(3, 2, torch.relu)\n",
        "print(layer1(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pprE8X5EKBD6",
        "outputId": "b8c59b10-5231-40e5-dbd9-23441fe5f77f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000, 13.9383]], grad_fn=<StackBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super(Model, self).__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(input_size, 1024),\n",
        "        nn.BatchNorm1d(1024),\n",
        "        nn.GELU(),\n",
        "\n",
        "        nn.Linear(1024, 512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.GELU(),\n",
        "\n",
        "        nn.Linear(512, output_size)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "cvd9lI5JKJNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''model1 = Model(3, 10)\n",
        "model1(x)'''"
      ],
      "metadata": {
        "id": "I0T9sYVOLC_q",
        "outputId": "9427b16a-ae8f-437a-83ee-097ad5a71cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model1 = Model(3, 10)\\nmodel1(x)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 436
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "transform_modified = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "dataset = MNIST(root = 'data/', download = True, transform = transform_modified, train=True)\n",
        "\n",
        "train_dataset, test_dataset = random_split(\n",
        "    dataset,\n",
        "    [50000, 10000],\n",
        "    generator=torch.Generator().manual_seed(10)\n",
        ")\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
        "test_loader = DataLoader(test_dataset, batch_size, shuffle = False)"
      ],
      "metadata": {
        "id": "4PRu8pctLFeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_model = Model(28*28, 10)"
      ],
      "metadata": {
        "id": "8KtAmG-bLc8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimiser = torch.optim.AdamW(mnist_model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "8jekGCguLioO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in range(20):\n",
        "    mnist_model.train()\n",
        "    loss_sum = 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader):\n",
        "        images = images.view(images.size(0), -1)\n",
        "\n",
        "        output = mnist_model(images)\n",
        "        loss = loss_fn(output, labels)\n",
        "\n",
        "        optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "        loss_sum += loss.item()\n",
        "\n",
        "    print(loss_sum / len(train_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzDWdYkJLlfZ",
        "outputId": "24985c7b-be12-4ba7-d8ee-ec33dbf54ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:21<00:00, 18.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.17441733080007688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:20<00:00, 18.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.07327943459353255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:21<00:00, 18.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.04766256045883574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:20<00:00, 19.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.034277327287265714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:21<00:00, 18.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.026768004170397434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:20<00:00, 19.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.02131284086171852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:21<00:00, 18.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.020413851937996056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:20<00:00, 19.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.016247809072524724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:21<00:00, 18.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.014636225268796153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:20<00:00, 19.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01122287311326966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:21<00:00, 18.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.012528994000036582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:20<00:00, 19.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01430303204985981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:21<00:00, 18.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.011107750054214523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:20<00:00, 19.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.008947011114515261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:21<00:00, 17.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.009070080457660315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:20<00:00, 19.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.008120166680068755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:21<00:00, 18.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.006435210481347085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:20<00:00, 18.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0038687916622223073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:21<00:00, 18.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01425689705068429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:20<00:00, 18.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.008122342527559523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.view(images.size(0), -1)\n",
        "        outputs = mnist_model(images)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "val_accuracy = correct / total\n",
        "print(\"Validation Accuracy:\", val_accuracy)"
      ],
      "metadata": {
        "id": "-G1c_ebZd8Pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3db6784c-e2dc-4c69-9692-cd878891d7ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def generate_kaggle_submission(model, output_csv_path=\"submission.csv\",\n",
        "    batch_size=128, device=None):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    test_dataset = MNIST(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform_modified   # <-- SAME normalization\n",
        ")\n",
        "\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, _ in test_loader:\n",
        "            # Flatten the images to match the model's expected input size\n",
        "            images = torch.flatten(images, start_dim=1)\n",
        "\n",
        "            outputs = model(images)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_predictions.append(preds)\n",
        "\n",
        "    all_predictions = torch.cat(all_predictions).numpy()\n",
        "\n",
        "    submission_df = pd.DataFrame({\n",
        "        \"ImageId\": range(1, len(all_predictions) + 1),\n",
        "        \"Label\": all_predictions\n",
        "    })\n",
        "\n",
        "    submission_df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Submission file saved to {output_csv_path}\")\n",
        "\n",
        "generate_kaggle_submission(mnist_model)"
      ],
      "metadata": {
        "id": "XohEQgWiLnNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e03b782-6bfc-46bb-b948-6696ca102c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file saved to submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YsvIzaMHV616"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}